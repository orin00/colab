{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0398eb4f-f36c-4307-861a-40765caeddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver # 제어가 가능한 Webdriver 크롬 브라우저\n",
    "from selenium.webdriver.common.by import By # select를 위한 선택자(CCS,ID,CLASS,NAME, XPATH 등)\n",
    "from selenium.webdriver.common.keys import Keys # 키보드에 있는 키를 사용하기 위한 모듈\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1d1bdaa-c1d1-48ba-9e34-76edb7a68457",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.saramin.co.kr/zf_user/jobs/list/job-category'\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# 경력 선택(신입)\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[1]/button')))\n",
    "career_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[1]/button')\n",
    "career_elm.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[1]/div/div[1]/div[1]/label')))\n",
    "career_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[1]/div/div[1]/div[1]/label')\n",
    "career_elm.click()\n",
    "\n",
    "\n",
    "# 학력 선택(무관)\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[2]/button')))\n",
    "edu_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[2]/button')\n",
    "edu_elm.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[2]/div/div[1]/div/label')))\n",
    "edu_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[1]/div[2]/div/div[1]/div/label')\n",
    "edu_elm.click()\n",
    "\n",
    "# 지역 선택 (서울 전체)\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/ul/li[2]/button')))\n",
    "loc_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/ul/li[2]/button')\n",
    "loc_elm.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_area_lastDepth_101000\"]/li[1]/div/label')))\n",
    "loc_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_area_lastDepth_101000\"]/li[1]/div/label')\n",
    "loc_elm.click()\n",
    "\n",
    "# 직업 선택(IT개발, 데이터)\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/ul/li[1]/button/span[1]')))\n",
    "job_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/ul/li[1]/button/span[1]')\n",
    "job_elm.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/div/div[1]/div[2]/div[1]/button[6]')))\n",
    "job_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_main_wrapper\"]/div[2]/div/div[1]/div[2]/div[1]/button[6]')\n",
    "job_elm.click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"sp_job_category_subDepth_2\"]/div[1]/label')))\n",
    "job_elm = driver.find_element(By.XPATH, '//*[@id=\"sp_job_category_subDepth_2\"]/div[1]/label')\n",
    "job_elm.click()\n",
    "\n",
    "# 검색하기 버튼 클릭\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search_btn\"]')))\n",
    "search_elm = driver.find_element(By.XPATH, '//*[@id=\"search_btn\"]')\n",
    "search_elm.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d32d8601-51e1-4917-a119-bd06f8a6cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4c35e0c-43b5-4806-a3ea-0fc8286c058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_info(soup):\n",
    "    company = [soup.select('.str_tit')[i].text.strip() for i in range(0,len(soup.select('.str_tit')),2)]\n",
    "    title = [soup.select('.str_tit')[i].text.strip() for i in range(1,len(soup.select('.str_tit')),2)]\n",
    "    stacks=[]\n",
    "    for i in soup.select('.job_sector'):\n",
    "        st = []\n",
    "        for j in i.select('span'):\n",
    "            st.append(j.text)\n",
    "        stacks.append(st)\n",
    "    loc = [i.text for i in soup.select('.work_place')]\n",
    "    career = [i.text for i in soup.select('.career')]\n",
    "    edu = [i.text for i in soup.select('.education')]\n",
    "    last_date = [i.text for i in soup.select('.support_detail>.date')]\n",
    "    input_date = [i.text for i in soup.select('.deadlines')]\n",
    "    main_url = 'https://www.saramin.co.kr'\n",
    "    link = [main_url + i['href'] for i in soup.select('.job_tit>a.str_tit')]\n",
    "\n",
    "    dic = {'company' : company,\n",
    "       'title': title,\n",
    "       'stack' : stacks,\n",
    "       'local' : loc,\n",
    "       'education': edu,\n",
    "       'career' : career,\n",
    "       'deadline' : last_date,\n",
    "       'upload' : input_date,\n",
    "       'url' : link}\n",
    "\n",
    "    return pd.DataFrame(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14eda71b-801e-4c9a-8211-d8716152ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parser_info(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c2c8838-2cc6-4d9c-a079-fbec6363fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_elm = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[5]/div/div[1]/span/em')\n",
    "total_count = int(tc_elm.text)\n",
    "page_cnt = math.ceil(total_count / 50)\n",
    "page_cnt\n",
    "end_cnt = page_cnt%10\n",
    "ten_cnt = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8da7fc8c-1eb5-4665-aeed-94ac5cd28c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 데이터 갯수가 501개 미만일 때\n",
    "## 2. 데이터 갯수가 501개 이상 ~ 1001개 미만일 때\n",
    "## 3. 데이터 갯수가 1001개 이상일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7335a974-adfb-4602-85c8-bc1d8398f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page : 2\n",
      "page : 3\n",
      "page : 4\n",
      "page : 5\n",
      "page : 6\n",
      "page : 7\n",
      "page : 8\n",
      "page : 9\n",
      "page : 10\n",
      "page : 다음\n",
      "page : 12\n",
      "page : 13\n",
      "page : 14\n",
      "page : 15\n",
      "page : 16\n",
      "page : 17\n",
      "page : 18\n",
      "page : 19\n",
      "page : 20\n"
     ]
    }
   ],
   "source": [
    "## 1. 데이터 갯수가 501개 미만일 때\n",
    "if total_count < 501:\n",
    "    for i in range(2, page_cnt + 1):\n",
    "        page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({j})')\n",
    "        print('page :',page_elm.text)\n",
    "        page_elm.click()\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        new_df = parser_info(soup)\n",
    "        df = pd.concat([df,new_df])\n",
    "     \n",
    "elif total_count < 1001:\n",
    "    for i in range(page_cnt//10):\n",
    "        if i < 1:\n",
    "            for j in range(2,12):\n",
    "                page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({j})')\n",
    "                print('page :',page_elm.text)\n",
    "                page_elm.click()\n",
    "                time.sleep(2)\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                new_df = parser_info(soup)\n",
    "                df = pd.concat([df,new_df])\n",
    "               \n",
    "        else:\n",
    "            if page_cnt%10 == 0:\n",
    "                end_cnt = ten_cnt\n",
    "            for k in range(3,end_cnt+2):\n",
    "                time.sleep(2)\n",
    "                page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({k})')\n",
    "                print('page :',page_elm.text)\n",
    "                page_elm.click()\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                new_df = parser_info(soup)\n",
    "                df = pd.concat([df,new_df])\n",
    "               \n",
    "else:\n",
    "    for i in range(page_cnt//10):\n",
    "        if i < 1:\n",
    "            for j in range(2,12):\n",
    "                page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({j})')\n",
    "                print('page :',page_elm.text)\n",
    "                page_elm.click()\n",
    "                time.sleep(2)\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                new_df = parser_info(soup)\n",
    "                df = pd.concat([df,new_df])\n",
    "              \n",
    "        elif i == (page_cnt//10) - 1:\n",
    "            for k in range(3,12):\n",
    "                time.sleep(2)\n",
    "                page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({k})')\n",
    "                print('page :',page_elm.text)\n",
    "                page_elm.click()\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                new_df = parser_info(soup)\n",
    "                df = pd.concat([df,new_df])\n",
    "                \n",
    "        else:\n",
    "            for k in range(3,13):\n",
    "                time.sleep(2)\n",
    "                page_elm = driver.find_element(By.CSS_SELECTOR, f'#default_list_wrap > div > button:nth-child({k})')\n",
    "                print('page :',page_elm.text)\n",
    "                page_elm.click()\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                new_df = parser_info(soup)\n",
    "                df = pd.concat([df,new_df])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21745927-6c6d-463a-ad75-045c0c4e712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today().strftime('%Y%m%d')\n",
    "df.to_excel(f'./취업정보/취업정보_{today}.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f48df-18df-4d3c-8305-e303de719840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
