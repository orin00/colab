{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRRWmNiZGU87w8b8bj9FgC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orin00/colab/blob/main/240422_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqFvSi8k1yxz"
      },
      "outputs": [],
      "source": [
        "!pip install imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import glob # 파일 경로, 폴더 생성\n",
        "import matplotlib.pyplot as plt # 이미지 확인\n",
        "import numpy as np\n",
        "import os # 외부 파일 사용\n",
        "import PIL # Python Image Library : 이미지 파일 불러오기\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import imageio\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "UtF0OvzU3Sas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 데이터셋만 사용, test 데이터는 불필요\n",
        "# 생성모델이기 떄문에 생성되는 데이터만 필요하고 생성데이터와 테스트데이터의 비교는 불필요\n",
        "(train_images, train_labels), (_,_) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "bFS0IJss3SjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape\n",
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "NvWMOIHw3SlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 이미지 확인\n",
        "fig, axes = plt.subplots(3, 5)\n",
        "fig.set_size_inches(8, 5)\n",
        "\n",
        "for i in range(15):\n",
        "    ax = axes[i//5, i%5]\n",
        "    ax.imshow(train_images[i], cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(str(train_labels[i]))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aHusw9_w3Sn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3차원 이미지 데이터로 변경\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
      ],
      "metadata": {
        "id": "Ed9evRDC3SrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "QeRD3nLz3SvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0]"
      ],
      "metadata": {
        "id": "s-OVc_DV3Sy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 데이터 스케일링\n",
        "# train_images = train_images / 255 # 0 ~ 1 사이의 값 (MINMAX Scaling)\n",
        "train_images = (train_images - 127.5) / 127.5 # -1 ~ 1 사이의 값"
      ],
      "metadata": {
        "id": "q4FDziZW3S4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## train dataset의 크기 지정 (그래픽 카드를 사용해야 하므로 크기 조정 미리 하는게 나음)\n",
        "BUFFER_SIZE = train_images.shape[0]\n",
        "BATCH_SIZE = 256 # 한번에 학습되는 양을 조금 줄임"
      ],
      "metadata": {
        "id": "h9WZwICH3S6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Batch 지정 및 데이터 셔플\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "3ISeaEzF3aFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "3a4i1cmU3aCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 만들기\n",
        "# 생성자(Generator)\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    # 입력층인데... 1차원 데이터로 입력받음. 7*7*256(12544) Node로 전달\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization()) # BatchNormalization() Batch_size 로 나눈것을 합칠때 값들을 정규분포 형태로 합칠 수 있도록\n",
        "    model.add(layers.LeakyReLU()) # 손실 함수\n",
        "\n",
        "    model.add(layers.Reshape((7,7,256))) # 데이터셋 Upscaling\n",
        "    assert model.output_shape == (None, 7, 7, 256) # 모델 출력 형태를 확인해서 알려줌\n",
        "\n",
        "    ## CNN층 설계\n",
        "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False)) # Conv2DTranspose는 역합성곱으로, 크기는 그대로고 채널 수만 줄임\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    ## 2번째 CNN층 설계\n",
        "    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False)) # padding='same'은 크기를 줄이지 않겠다. use_bias=False는 계산량 줄이려고.\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    ## 최종 출력 형태인 28*28*1을 만들기\n",
        "    model.add(layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))\n",
        "    # train_images = (train_images - 127.5) / 127.5 해서\n",
        "    # -1 ~ 1 사이의 값이 나오니까 하이퍼볼릭 탄젠트 함수 사용\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rs6YegQI3Z_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "values = tf.random.normal([1,100])\n",
        "generator_image = generator(values, training=False)\n",
        "plt.imshow(generator_image[0,:,:,0], cmap='gray')\n",
        "# 아무것도 학습이 안 된 상태의 결과물\n",
        "# 진짜 아무 의미없는 값이나 출력한 거"
      ],
      "metadata": {
        "id": "CQEh2XoX3Z9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 감별자 만들기 (Discriminator) == CNN 기반 이진 분류기\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3)) # 과적합 방지 => 학습된 가중치의 30%를 삭제\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # 출력층\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model"
      ],
      "metadata": {
        "id": "N5J4JUs_3Z6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generator_image)\n",
        "print(decision)"
      ],
      "metadata": {
        "id": "DcUyr2r83dkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 손실 함수와 옵티마이저 정의\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True) # 이진 분류 손실 함수"
      ],
      "metadata": {
        "id": "q1WxIFq43dhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 감별자 손실\n",
        "## 감별자는 가짜를 0으로 감별하고, 진짜를 1로 감별\n",
        "## real 이미지에 대한 감별결과 : 1\n",
        "## fake 이미지에 대한 감별결과 : 0\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    # 1로 만들어진 배열을 생성하고 real_output과 비교\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    # 0으로 만들어진 배열을 생성하고 fake_output과 비교\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "ufWax5HG3deb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 생성자 손실 함수\n",
        "## 생성자는 0인 데이터를 생성하지만 실제 1인 데이터로 판단하도록 손실값을 만듬\n",
        "## 생성자와 감별자는 같은 손실함수를 사용할 수 없다.\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "s9qTllfU3Z27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 경사하강법(optimizer)는 두 네트워크를 별도로 훈련하기 때문에 서로 따로 정의하지만\n",
        "## 종류는 같은 것을 써도 된다.(Adam)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4) # 괄호 안의 숫자'1e-4'는 learnning rate = 0.0001\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "ZVBogAM03hVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 체크포인트 저장\n",
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
        "                                 discriminator_optimizer = discriminator_optimizer,\n",
        "                                 generator = generator,\n",
        "                                 discriminator = discriminator)"
      ],
      "metadata": {
        "id": "leRXM2Ls3hTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 훈련 루프 정의하기\n",
        "EPOCHS = 50\n",
        "noise_dim = 100 # 노이즈 벡터의 차원\n",
        "num_examples_to_generate = 16 # 이미지 갯수\n",
        "\n",
        "# 생성자는 입력으로 임의의 시드값을 받게 되고 입력을 받으면 훈련 루프가 실행\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim]) # 입력으로 쓰이게 될 랜덤한 값의 seed"
      ],
      "metadata": {
        "id": "BiD0VxLc3hQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 이미지 한장 학습\n",
        "## 생성자 : 입력을 받고 가짜 이미지 생성 -> 실제와 유사하도록 가중치 업데이트\n",
        "## 감별자 : 진짜와 가짜를 입력으로 받고 실제와 가짜를 잘 분류하는 방향으로 가중치 업데이트\n",
        "def train_step(images):\n",
        "    ## 노이즈 입력 생성 : 입력값\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    ## tf.GradientTape() : 자동 미분 모듈\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # 가짜 이미지 생성\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # 판별값 진짜 몇 %, 가짜 몇 %\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # 손실 함수 계산 => loss 값 뽑기\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # 손실 함수 계산 결과에 따라 그래디언트 계산\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # 옵티마이저 적용\n",
        "    # trainable_variables : 학습 가능한 변수들\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "-MTHFaD43hN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epoch+1, seed)\n",
        "\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "        print(f'Time for epochs {epoch+1} is {time.time()-start} sec')\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epochs, seed)"
      ],
      "metadata": {
        "id": "LT4vHLMI3hLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(predictions[i,:,:,0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'image_at_epoch_{epoch}.png')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZHM21QHU3hJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "JRN2U42A3Z0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}